# 使用 Python 进行梯度下降

> 原文：<https://pyimagesearch.com/2016/10/10/gradient-descent-with-python/>

> *几乎所有的深度学习都是由一个非常重要的算法驱动的:随机梯度下降(SGD)* 。
> 
> <cite>— [Goodfellow, Bengio, and Courville (2016)](https://www.deeplearningbook.org/)</cite>

至此，我们对参数化学习的概念有了很强的理解。我们之前讨论了*参数化学习*的概念，以及这种类型的学习如何使我们能够定义将输入数据映射到输出类标签的*评分函数*。

该评分函数由两个重要的*参数*定义；具体来说，我们的权重矩阵 ***W*** 和我们的偏置向量 ***b*** 。我们的评分函数接受这些参数作为输入，并返回每个输入数据点 *x* *[i]* 的预测。

我们还讨论了两种常见的损失函数:多类 SVM 损失和交叉熵损失。最基本的损失函数用于量化给定预测器(即一组参数)在对数据中的输入数据点进行分类时的“好”或“坏”程度。

鉴于这些构建模块，我们现在可以继续进行机器学习、神经网络和深度学习的*最重要的方面*——***优化*** 。优化算法是为神经网络提供动力并使其能够从数据中学习模式的引擎。在整个讨论中，我们已经了解到，获得高精度分类器是*依赖于*找到一组权重 ***W*** 和 ***b*** ，这样我们的数据点被正确分类。

**但是我们如何去寻找********获得*** **一个权重矩阵** ***W*** **和偏置向量** ***b*** **从而获得高的分类精度呢？**我们是否随机地初始化它们，评估，并一遍又一遍地重复，*希望*在*某个点*我们找到一组获得合理分类的参数？我们可以——但鉴于现代深度学习网络的参数数以千万计，我们可能需要很长时间才能盲目地发现一组合理的参数。***

 ***我们需要定义一个*优化算法*，而不是依靠纯粹的随机性，让我们*字面上改进* ***W* 和 *b*** 。在这一课中，我们将研究用于训练神经网络和深度学习模型的最常用算法— *梯度下降*。梯度下降有许多变体(我们也将谈到)，但是，在每种情况下，想法都是相同的:迭代地评估你的参数，计算你的损失，然后在将你的损失最小化的方向上迈出一小步。

## **使用 Python 进行梯度下降**

梯度下降算法有两种主要风格:

1.  标准的“普通”实现。
2.  更常用的优化“随机”版本。

在这一课中，我们将回顾基本的香草实现，以形成我们理解的基线。在我们理解了梯度下降的基础之后，我们将转向随机版本。然后我们将回顾一些可以添加到梯度下降中的“附加功能”,包括动量和内斯特罗夫加速度。

### **损失景观和优化面**

梯度下降法是一种在**损失景观**(也称为*优化表面*)上运行的*迭代优化算法*。典型的梯度下降示例是沿着 *x* 轴可视化我们的权重，然后沿着 *y* 轴可视化一组给定权重的损失(**图 1** 、*左*):

正如我们所看到的，我们的损失情况有许多峰值和谷值，这取决于我们的参数值。每个峰值都是代表极高损失区域的*局部最大值*——在整个损失范围内损失最大的局部最大值是*全局最大值*。类似地，我们也有*局部最小值*，它代表许多小的损失区域。

损失范围内损失最小的局部最小值就是我们的*全局最小值*。在理想世界中，我们希望找到这个全局最小值，确保我们的参数取最佳值。

所以这就提出了一个问题:*“如果我们想达到一个全局最小值，为什么不直接跳到* *上去呢？在剧情上清晰可见？”*

这就是问题所在——我们看不到损失景观。我们不知道它看起来像什么。如果我们是一个优化算法，我们将被*盲目地*放置在地块上的某个地方，不知道我们面前的风景是什么样子，我们将不得不导航到损失最小，而不会意外地爬到局部最大值的顶部。

就我个人而言，我从来不喜欢这种损失景观的可视化——它太简单了，而且它经常让读者认为梯度下降(及其变体)最终会找到局部或全局最小值。这种说法是不正确的，尤其是对于复杂的问题来说。相反，让我们来看一个不同的损失景观的可视化，我相信它能更好地描述这个问题。这里我们有一个碗，类似于你用来吃麦片或喝汤的碗(**图一**、*右*)。

我们碗的表面是损失景观，是损失函数的一个*图*。我们的损失景观和你们的谷物碗的区别在于，你们的谷物碗只存在于三维空间，而你们的损失景观存在于*多维度*，可能是几十、几百、几千维。

给定一组参数**(权重矩阵)和 ***b*** (偏置向量)，沿碗表面的每个位置对应于一个*特定损失值*。我们的目标是尝试 ***W*** 和 ***b*** 的不同值，评估它们的损失，然后向(理想情况下)损失更低的更优值迈进一步。**

 **### **梯度下降中的“梯度”**

为了让我们对梯度下降的解释更直观一点，让我们假设我们有一个机器人——让我们把他命名为乍得(**图二**，*左*)。当执行梯度下降时，我们随机地将 Chad 放在损失图的某个地方(**图 2** ，*右*)。

现在乍得的工作是航行到盆地的底部(那里损失最小)。看起来很简单，对吗？查德所要做的就是调整自己的方向，让自己面向“下坡”，然后沿着斜坡一直走到碗的底部。

但问题是:乍得不是一个非常聪明的机器人。查德只有一个传感器——这个传感器允许他获取自己的参数***【W】****和 ***b*** ，然后计算损失函数 *L* 。因此，查德能够计算出他在损失地形上的相对位置，但是他完全不知道他应该朝哪个方向走一步才能更接近盆地的底部。*

 *查德要做什么？ ***答案是应用梯度下降。*** 查德需要做的就是顺着坡度的斜率 ***W*** 。我们可以使用以下等式计算所有维度上的梯度 ***W*** :

**【①**

 **在维度 *>* 1 中，我们的梯度变成了偏导数的*向量。这个等式的问题是:*

1.  这是梯度的近似值。
2.  它慢得令人痛苦。

实际上，我们使用*解析梯度*来代替。该方法精确而快速，但由于偏导数和多变量微积分，实施起来极具挑战性。证明梯度下降的多变量微积分的完整推导不在本课范围内。如果你有兴趣学习更多关于数值和解析梯度的知识，我会推荐[齐布列夫斯基的这个讲座](https://www.youtube.com/watch?v=ruuW4-InUxM)，吴恩达的 CS229 机器学习笔记，以及[的 CS231n 笔记](https://cs231n.github.io/optimization-1/)。

为了便于讨论，简单地内化梯度下降是什么:通过在损失最小化的方向上迈出一步的迭代过程，尝试优化我们的参数以获得低损失和高分类精度。

### **把它当成凸问题(即使不是)**

使用**图 1** ( *右*)中的碗作为损失景观的可视化也允许我们在现代神经网络中得出一个重要的结论——**我们将损失景观作为凸问题来处理，** ***即使它不是*** **。**如果某个函数 *F* 是凸的，那么所有局部极小值也是全局极小值。这个想法非常符合碗的形象。我们的优化算法只需在碗的顶部绑上一对滑雪板，然后慢慢滑下斜坡，直到我们到达底部。

问题是，我们应用神经网络和深度学习算法解决的几乎所有问题都是*而不是*简洁的凸函数。相反，在这个碗中，我们会发现尖峰状的峰，更像峡谷的谷，陡峭的下降，甚至是损耗急剧下降但又急剧上升的槽。

鉴于我们的数据集的非凸性质，为什么我们要应用梯度下降？答案很简单:*因为它做得足够好*。引用[古德菲勒等人(2016)](https://www.deeplearningbook.org/) :

> 优化算法可能不能保证在合理的时间内达到局部最小值，但它通常能足够快地找到[loss]函数的一个非常低的值。

在训练深度学习网络时，我们可以设定找到局部/全局最小值的高期望，但这种期望很少与现实相符。相反，我们最终找到了一个低损耗的区域— *这个区域甚至可能不是局部最小值*，但实际上，这证明了**足够好**。

### **偏见的诡计**

在我们继续实现梯度下降之前，我想花时间讨论一种称为“偏差技巧”的技术，这是一种将我们的权重矩阵***【W】****和偏差向量 ***b*** 组合成一个*单个*参数的方法。回想一下我们之前的决策，我们的评分函数定义为:*

 ***②![f(x_{i}, W, b) = Wx_{i} + b](img/dd16926f04112061156ad4f9a73ee93f.png "f(x_{i}, W, b) = Wx_{i} + b")**

 **无论是从解释*还是从实现*的角度来看，跟踪两个独立的变量通常都很繁琐——为了完全避免这种情况，我们可以将 ***W*** 和 ***b*** 组合在一起。为了组合偏差和权重矩阵，我们向我们的输入数据 ***X*** 添加一个额外的维度(即列),该维度保持常数 1，这就是我们的偏差维度。

通常我们会将新的维度添加到每个单独的*x[I]中，作为第一个维度或最后一个维度。实际上，这并不重要。我们可以选择任意位置将一列 1 插入到我们的设计矩阵中，只要它存在。这样做允许我们通过单个矩阵乘法来重写我们的评分函数:*

**(3)** ![f(x_{i}, W) = Wx_{i}](img/9461cfd50f811d69035d1ebf7fed00c6.png "f(x_{i}, W) = Wx_{i}")

同样，我们可以在这里省略掉 *b* 项，因为它是*嵌入到我们的权重矩阵中的。*

在我们之前的“动物”数据集中的例子的上下文中，我们已经处理了 32 张 *×* 32 张 *×* 3 张总共 3072 像素的图像。每一个*x[I]都用一个矢量【3072 *×* 1】来表示。现在，添加一个常数值为 1 的维度会将向量扩展为[3073 *×* 1]。类似地，组合偏差和权重矩阵也将我们的权重矩阵 ***W*** 扩展为【3】×*3073】而不是【3】×*×3072】。这样，我们可以将偏差视为权重矩阵*中的一个*可学习参数，我们不必在单独的变量中明确跟踪它。*

为了形象化偏差技巧，考虑图 3 ( *左*)中我们*分离*权重矩阵和偏差。到目前为止，这个图描述了我们如何考虑我们的得分函数。但是相反，我们可以*将****W****和 ***b*** 组合在一起，前提是我们在每个 *x [i]* 中插入一个新列，其中每个条目都是一个(**图 3** ，*右*)。应用偏差技巧允许我们只学习单一的权重矩阵，因此我们倾向于使用这种方法来实现。对于所有未来的例子，每当我提到 ***W*** 时，假设偏差向量 ***b*** 也隐式包含在权重矩阵中。*

 ****备注:*** 我们实际上是在**图 3** 的特征向量中插入一个新的*行*，其值为`1`。你也可以添加一个*列*到我们的填充了 1 的特征矩阵中。那么，哪个是正确的呢？这实际上取决于你如何执行你的线性代数，以及你如何转置每个矩阵。您将看到两者都在实施中使用，我想确保您现在已为此做好准备。

### **梯度下降的伪代码**

下面我为标准的普通梯度下降算法添加了类似 Python 的伪代码([伪代码，灵感来自 cs231n 幻灯片](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture3.pdf)):

```
while True:
	Wgradient = evaluate_gradient(loss, data, W)
	W += -alpha * Wgradient
```

这个伪代码就是*梯度下降的所有*变体的基础。我们从**线 1** 开始循环，直到满足某些条件，通常是:

1.  指定数量的时期已经过去(意味着我们的学习算法已经“看到”每个训练数据点 *N* 次)。
2.  我们的损失已经变得*足够低*或者训练精度*令人满意的高*。
3.  损失在随后的 *M* 个时期没有改善。

**第 2 行**然后调用一个名为`evaluate_gradient`的函数。该函数需要三个参数:

1.  `loss`:用于计算超过当前参数`W`和输入`data`的损失的函数。
2.  `data`:我们的训练数据，其中每个训练样本由一个图像(或特征向量)表示。
3.  我们正在优化的实际权重矩阵。我们的目标是应用梯度下降来找到一个产生最小损失的`W`。

`evaluate_gradient`函数返回一个 *K* 维的向量，其中 *K* 是我们的图像/特征向量的维数。`Wgradient`变量是实际的梯度，其中我们为每个维度都有一个梯度条目。

然后我们在**线 3** 上应用*渐变下降*。我们把我们的`Wgradient`乘以`alpha` ( *α* ，就是我们的*学习率*。**学习率控制着我们一步的大小。**

实际上，你会花*很多*时间来寻找 *α* 的最优值——这是*到目前为止*你的模型中最重要的参数。如果 *α* 太大，你会花所有的时间在亏损的情况下反弹，而不会真正“下降”到谷底(除非你的随机反弹纯属运气)。相反，如果 *α* 太小，那么将需要*多次*(可能是非常多次)迭代才能到达盆地底部。寻找 *α* 的最佳值将会给你带来很多麻烦——你将会花费大量的时间来为你的模型和数据集寻找这个变量的最佳值。

### **在 Python 中实现基本梯度下降**

现在我们知道了梯度下降的基础知识，让我们用 Python 实现它，并用它对一些数据进行分类。打开一个新文件，将其命名为`gradient_descent.py`，并插入以下代码:

```
# import the necessary packages
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.datasets import make_blobs
import matplotlib.pyplot as plt
import numpy as np
import argparse

def sigmoid_activation(x):
	# compute the sigmoid activation value for a given input
	return 1.0 / (1 + np.exp(-x))

def sigmoid_deriv(x):
	# compute the derivative of the sigmoid function ASSUMING
	# that the input `x` has already been passed through the sigmoid
	# activation function
	return x * (1 - x)
```

**第 2-7 行**导入我们需要的 Python 包。我们之前已经看到了所有这些导入，除了`make_blobs`，一个用于创建正态分布数据点的“blobs”的函数——当从头开始测试或实现我们自己的模型时，这是一个方便的函数。

然后我们在第 9 行的**上定义`sigmoid_activation`函数。绘制时，该函数将类似于一条“S”形曲线(**图 4** )。我们称之为 ***激活函数*** 是因为该函数会“激活”并触发“on”(输出值 *>* 0 *)。* 5)或“关”(输出值 *<* = 0 *)。* 5)基于输入`x`。**

**第 13-17 行**定义了 sigmoid 函数的*导数*。我们需要计算这个函数的导数来得到实际的梯度。梯度使我们能够沿着优化曲面的斜坡向下行进。我们将在单独的课程中更详细地讲述这一点。

`predict`函数应用我们的 sigmoid 激活函数，然后根据神经元是否触发(1)来设定阈值(0):

```
def predict(X, W):
	# take the dot product between our features and weight matrix
	preds = sigmoid_activation(X.dot(W))

	# apply a step function to threshold the outputs to binary
	# class labels
	preds[preds <= 0.5] = 0
	preds[preds > 0] = 1

	# return the predictions
	return preds
```

给定一组输入数据点`X`和权重`W`，我们对它们调用`sigmoid_activation`函数来获得一组预测(**行 21** )。然后，我们对预测进行阈值处理:值为 *<* = 0 *的任何预测。* 5 被设置为`0`，而任何具有值 *>* 0 *的预测。* 5 设置为`1` ( **第 25 行和第 26 行**)。然后预测返回到**行 29** 上的调用函数。

虽然有其他(更好的)替代 sigmoid 激活函数的方法，但它为我们讨论神经网络、深度学习和基于梯度的优化提供了一个极好的起点。我将在以后的课程中讨论其他激活函数，但目前，只要记住 sigmoid 是一个非线性激活函数，我们可以用它来设定预测阈值。

接下来，让我们解析我们的命令行参数:

```
 # construct the argument parse and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-e", "--epochs", type=float, default=100,
	help="# of epochs")
ap.add_argument("-a", "--alpha", type=float, default=0.01,
	help="learning rate")
args = vars(ap.parse_args())
```

我们可以为脚本提供两个(可选的)命令行参数:

*   当我们使用梯度下降来训练我们的分类器时，我们将使用的历元数。
*   `--alpha`:梯度下降的*学习率*。我们通常将 0.1、0.01 和 0.001 视为初始学习率值，但同样，这是一个超参数，您需要针对自己的分类问题进行调整。

既然我们的命令行参数已被解析，让我们生成一些数据进行分类:

```
# generate a 2-class classification problem with 1,000 data points,
# where each data point is a 2D feature vector
(X, y) = make_blobs(n_samples=1000, n_features=2, centers=2,
	cluster_std=1.5, random_state=1)
y = y.reshape((y.shape[0], 1))

# insert a column of 1's as the last entry in the feature
# matrix -- this little trick allows us to treat the bias
# as a trainable parameter within the weight matrix
X = np.c_[X, np.ones((X.shape[0]))]

# partition the data into training and testing splits using 50% of
# the data for training and the remaining 50% for testing
(trainX, testX, trainY, testY) = train_test_split(X, y,
	test_size=0.5, random_state=42)
```

在第 41 行的**上，我们调用`make_blobs`，它生成 1000 个数据点，分成两类。这些数据点是 2D，意味着“特征向量”的长度是 2。这些数据点的标签不是`0`就是`1`。我们的目标是训练一个正确预测每个数据点的类别标签的分类器。**

**第 48 行**应用了“偏差技巧”(详见上文)，通过插入一个全新的 1 列作为我们设计矩阵`X`的最后一项，允许我们明确跳过*跟踪我们的偏差向量 ***b*** 。添加包含跨越所有特征向量的常量值的列允许我们将我们的偏差视为权重矩阵 内的*可训练参数* ***，而不是视为完全独立的变量。****

 *一旦我们插入了 1 的列，我们就将数据划分到第 52 行和第 53 行的训练和测试部分，使用 50%的数据进行训练，50%的数据进行测试。

我们的下一个代码块使用均匀分布处理随机初始化我们的权重矩阵，使其具有与我们的输入特征相同的维数(包括偏差):

```
# initialize our weight matrix and list of losses
print("[INFO] training...")
W = np.random.randn(X.shape[1], 1)
losses = []
```

你可能还会看到*零*和*一*权重初始化，但正如我们将在后面的课程中发现的，良好的初始化对于在合理的时间内训练神经网络来说是关键的**，因此随机初始化和简单的启发式算法在绝大多数情况下都会胜出( [Mishkin 和 Matas，2016](https://arxiv.org/abs/1511.06422) )。**

 **初始化一个列表来记录每个时期后我们的损失。在 Python 脚本的最后，我们将绘制损失图(理想情况下，损失会随着时间的推移而减少)。

我们所有的变量现在都已初始化，所以我们可以继续实际的训练和梯度下降程序:

```
# loop over the desired number of epochs
for epoch in np.arange(0, args["epochs"]):
	# take the dot product between our features "X" and the weight
	# matrix "W", then pass this value through our sigmoid activation
	# function, thereby giving us our predictions on the dataset
	preds = sigmoid_activation(trainX.dot(W))

	# now that we have our predictions, we need to determine the
	# "error", which is the difference between our predictions and
	# the true values
	error = preds - trainY
	loss = np.sum(error ** 2)
	losses.append(loss)
```

在**61 号线**上，我们开始循环`--epochs`的供应数量。默认情况下，我们允许训练程序总共“看到”每个训练点 100 次(因此，100 个纪元)。

**行 65** 取我们的*整个*训练集`trainX`和我们的权重矩阵`W`之间的点积。这个点积的输出通过 sigmoid 激活函数，产生我们的预测。

给定我们的预测，下一步是确定预测的“误差”，或者更简单地说，我们的*预测*和*真实值* ( **行 70** )之间的差异。**第 71 行**计算我们预测的最小平方误差，这是一个简单的损失，通常用于二元分类问题。这个训练程序的目标是最小化我们的最小平方误差。我们将这个`loss`添加到第 72 行**列表的`losses`中，这样我们就可以随时间绘制损失图。**

现在我们有了`error`，我们可以计算`gradient`，然后用它来更新我们的权重矩阵`W`:

```
	# the gradient descent update is the dot product between our
	# (1) features and (2) the error of the sigmoid derivative of
	# our predictions
	d = error * sigmoid_deriv(preds)
	gradient = trainX.T.dot(d)

	# in the update stage, all we need to do is "nudge" the weight
	# matrix in the negative direction of the gradient (hence the
	# term "gradient descent" by taking a small step towards a set
	# of "more optimal" parameters
	W += -args["alpha"] * gradient

	# check to see if an update should be displayed
	if epoch == 0 or (epoch + 1) % 5 == 0:
		print("[INFO] epoch={}, loss={:.7f}".format(int(epoch + 1),
			loss))
```

**第 77 行和第 78 行**处理梯度的计算，梯度是我们的数据点和误差之间的点积乘以我们预测的 sigmoid 导数。

**第 84 行**是我们算法中最关键的一步，也是实际梯度下降发生的地方。这里，我们通过在梯度的负方向上迈出一步来更新我们的权重矩阵`W`，从而允许我们向损失景观的盆地底部移动(因此，术语，*梯度下降*)。在更新我们的权重矩阵之后，我们检查是否应该向我们的终端显示更新(**第 87-89 行**)，然后继续循环，直到达到期望的历元数——梯度下降因此是一个*迭代算法*。

我们的分类器现在已经训练好了。下一步是评估:

```
# evaluate our model
print("[INFO] evaluating...")
preds = predict(testX, W)
print(classification_report(testY, preds))
```

为了实际使用我们的权重矩阵`W`进行预测，我们在`testX`上调用了`predict`方法，在**的第 93 行**上调用了`W`方法。给定预测，我们在终端的第 94 行上显示一个格式良好的分类报告。

我们的最后一个代码块处理(1)绘制*测试数据*以便我们可以可视化我们试图分类的数据集，以及(2)我们随时间的损失:

```
# plot the (testing) classification data
plt.style.use("ggplot")
plt.figure()
plt.title("Data")
plt.scatter(testX[:, 0], testX[:, 1], marker="o", c=testY[:, 0], s=30)

# construct a figure that plots the loss over time
plt.style.use("ggplot")
plt.figure()
plt.plot(np.arange(0, args["epochs"]), losses)
plt.title("Training Loss")
plt.xlabel("Epoch #")
plt.ylabel("Loss")
plt.show()
```

### **简单梯度下降结果**

要执行我们的脚本，只需发出以下命令:

```
$ python gradient_descent.py 
[INFO] training...
[INFO] epoch=1, loss=194.3629849
[INFO] epoch=5, loss=9.3225755
[INFO] epoch=10, loss=5.2176352
[INFO] epoch=15, loss=3.0483912
[INFO] epoch=20, loss=1.8903512
[INFO] epoch=25, loss=1.3532867
[INFO] epoch=30, loss=1.0746259
[INFO] epoch=35, loss=0.9074719
[INFO] epoch=40, loss=0.7956885
[INFO] epoch=45, loss=0.7152976
[INFO] epoch=50, loss=0.6547454
[INFO] epoch=55, loss=0.6078759
[INFO] epoch=60, loss=0.5711027
[INFO] epoch=65, loss=0.5421195
[INFO] epoch=70, loss=0.5192554
[INFO] epoch=75, loss=0.5011559
[INFO] epoch=80, loss=0.4866579
[INFO] epoch=85, loss=0.4747733
[INFO] epoch=90, loss=0.4647116
[INFO] epoch=95, loss=0.4558868
[INFO] epoch=100, loss=0.4478966
```

从**图 5** ( *左*我们可以看到，我们的数据集是明显线性可分的(即我们可以画一条线将两类数据分开)。我们的损失也急剧下降，开始非常高，然后迅速下降(*右*)。通过研究上面的终端输出，我们可以看到损耗下降的速度有多快。请注意，损失最初是 *>* 194，但下降到≈ 0 *。* 6 按纪元 50。到第 100 纪元训练终止时，我们的损失已经到 0 *。45。*

该图验证了我们的权重矩阵正在以允许分类器从训练数据中学习的方式被更新。我们可以在下面看到数据集的分类报告:

```
[INFO] evaluating...
             precision    recall  f1-score   support

          0       1.00      1.00      1.00       250
          1       1.00      1.00      1.00       250

avg / total       1.00      1.00      1.00       500
```

请注意*和*这两个类别是如何在 100%的时间内被正确分类的，这再次表明我们的数据集是:(1)线性可分的，以及(2)我们的梯度下降算法能够下降到低损失的区域，能够分离这两个类别。

也就是说，记住普通梯度下降算法的工作原理是很重要的。普通梯度下降只对每个历元执行一次权重更新*——在这个例子中，我们为我们的模型训练了 100 个历元，所以只发生了 100 次更新。根据权重矩阵的初始化和学习率的大小，我们可能无法学习到可以分离这些点的模型(即使它们是线性可分离的)。*

对于简单的梯度下降，你最好训练*更多的周期*和*更小的学习率*来帮助克服这个问题。然而，称为*随机梯度下降*的梯度下降的变体对每批训练数据的*执行权重更新，这意味着每个时期有*多个*权重更新。这种方法导致更快、更稳定的收敛。****************
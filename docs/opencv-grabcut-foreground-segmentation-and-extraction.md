# OpenCV GrabCut:前景分割和提取

> 原文：<https://pyimagesearch.com/2020/07/27/opencv-grabcut-foreground-segmentation-and-extraction/>

在本教程中，您将学习如何使用 OpenCV 和 GrabCut 来执行前景分割和提取。

在深度学习和实例/语义分割网络如 Mask R-CNN，U-Net 等之前。， **GrabCut 是*将图像的前景从背景中准确分割出来的方法*。**

GrabCut 算法的工作原理是:

*   接受带有*的输入图像，或者是* (1)一个**边界框**，它指定了我们想要分割的图像中对象的位置，或者是(2)一个**遮罩**，它的*近似于*分割
*   迭代地执行以下步骤:
    *   **步骤#1:** 通过高斯混合模型(GMM)估计前景和背景的颜色分布
    *   **步骤#2:** 在像素标签上构建马尔可夫随机场(即，前景对背景)
    *   **步骤#3:** 应用图割优化以达到最终分割

听起来很复杂，不是吗？

幸运的是，OpenCV 通过`cv2.grabCut`函数实现了 GrabCut，这使得应用 GrabCut 变得轻而易举(当然，前提是您知道该函数的参数以及如何调整它们)。

但是在你说:

> 嘿，阿德里安，GrabCut 算法不是旧闻了吗？
> 
> 难道我们不应该应用 Mask R-CNN、U-Net 或其他图像分割网络来分割背景和前景吗？

以上是深度学习和传统计算机视觉如何融合在一起的完美例子。

如果你以前用过 Mask R-CNN 或者 U-Net，你就知道这些深度神经网络*超级强大*，但是面具并不总是完美的。**实际上，你可以使用 GrabCut 来清理这些分段掩码**(我将在以后的文章中向你展示如何做)。

但与此同时，让我们了解一下 GrabCut 的基本原理。

**学习如何使用 OpenCV 和 GrabCut 进行前景分割，*继续阅读。***

## OpenCV GrabCut:前景分割和提取

在本教程的第一部分，我们将讨论 GrabCut，它通过`cv2.grabCut`函数在 OpenCV 中的实现，以及它的相关参数。

从这里，我们将学习如何通过以下两种方式用 OpenCV 实现 GrabCut:

1.  使用边界框进行 GrabCut 初始化
2.  使用掩码近似的 GrabCut 初始化

之后，我们将应用 GrabCut 并检查我们的结果。

### OpenCV 中的 GrabCut

`cv2.grabCut`函数具有以下签名:

```py
grabCut(img, mask, rect, bgdModel, fgdModel, iterCount[, mode]) ->
	mask, bgdModel, fgdModel
```

**为了获得对实现的完整理解，让我们回顾一下这些参数:**

*   ``img`` :输入图像，GrabCut 假设其为 8 位 3 通道图像(即 BGR 通道排序中的无符号 8 位整数)。
*   ``mask`` :输入/输出屏蔽。此遮罩被假定为单通道图像，具有无符号 8 位整数数据类型。如果使用边界框初始化(即`cv2.GC_INIT_WITH_RECT`)，该遮罩会自动初始化；否则，GrabCut 会假设您正在执行掩码初始化(`cv2.GC_INIT_WITH_MASK`)。
*   ``rect`` :包含要分割区域的边框矩形。该参数仅在将`mode`设置为`cv2.GC_INIT_WITH_MASK`时使用。
*   `bgModel`:grab cut 内部对*背景*建模时使用的临时数组。
*   ``fgModel``:grab cut 对*前景建模时使用的临时数组。*
*   ``iterCount``:grab cut 对前景和背景建模时将执行的迭代次数。迭代次数越多，GrabCut 运行的时间越长，理想情况下结果会更好。
*   ``mode`` :或者`cv2.GC_INIT_WITH_RECT`或者`cv2.GC_INIT_WITH_MASK`，分别取决于你是用边界框还是遮罩初始化 GrabCut。

现在我们已经了解了`cv2.grabCut`函数，包括它的参数和返回值，让我们继续将 GrabCut 应用于一个示例计算机视觉项目。

### 配置您的开发环境

按照我的 *[pip install opencv](https://pyimagesearch.com/2018/09/19/pip-install-opencv/)* 教程(包含 Ubuntu、macOS 和 Raspbian 的说明)，您现在可以使用包含 OpenCV 的 Python 虚拟环境来设置您的系统。

请注意 [PyImageSearch 不推荐也不支持 Windows 用于计算机视觉和深度学习开发](https://pyimagesearch.com/faqs/single-faq/can-you-help-me-do-___-on-windows/)。

### 项目结构

在我们继续之前，使用今天教程的 ***【下载】*** 部分。与这篇博文相关的 zip 文件。从那里，让我们用`tree`命令直接在终端中检查文件和文件夹的布局:

```py
$ tree --dirsfirst
.
├── images
│   ├── adrian.jpg
│   ├── lighthouse.png
│   └── lighthouse_mask.png
├── grabcut_bbox.py
└── grabcut_mask.py

1 directory, 5 files
```

使用这两个 Python 脚本，我们将学习如何使用两种方法执行 GrabCut(边界框初始化与遮罩初始化)。在下一节中，我们将从包围盒方法开始。

### 使用 OpenCV 的 GrabCut:使用边界框初始化

让我们开始用 OpenCV 实现 GrabCut 我们将从回顾边界框实现方法开始。

这里，我们将指定要在图像中分割的对象的边界框。边界框可以通过以下方式生成:

*   手动检查图像并标记边界框的 *(x，y)*-坐标
*   应用哈尔级联
*   利用 HOG +线性 SVM 检测目标
*   利用基于深度学习的对象检测器，如更快的 R-CNN、SSDs、YOLO 等。

**只要算法生成了包围盒，就可以配合 GrabCut 使用。**

出于我们今天演示脚本的目的，我们将手动*定义边界框 *(x，y)*-坐标(即，而不是应用自动对象检测器)。*

 *现在我们来看看 GrabCut 的包围盒初始化方法。

打开一个新文件，将其命名为`grabcut_bbox.py`，并插入以下代码:

```py
# import the necessary packages
import numpy as np
import argparse
import time
import cv2
import os

# construct the argument parser and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-i", "--image", type=str,
	default=os.path.sep.join(["images", "adrian.jpg"]),
	help="path to input image that we'll apply GrabCut to")
ap.add_argument("-c", "--iter", type=int, default=10,
	help="# of GrabCut iterations (larger value => slower runtime)")
args = vars(ap.parse_args())
```

我们从选择的导入开始这个脚本，即 OpenCV 和 NumPy(其余的构建在 Python 中)。请参考上面的*“配置您的开发环境”*部分，在您的系统上安装 Python、OpenCV 和相关软件。

我们的脚本处理两个[命令行参数](https://pyimagesearch.com/2018/03/12/python-argparse-command-line-arguments/):

```py
# load the input image from disk and then allocate memory for the
# output mask generated by GrabCut -- this mask should hae the same
# spatial dimensions as the input image
image = cv2.imread(args["image"])
mask = np.zeros(image.shape[:2], dtype="uint8")
```

```py
# define the bounding box coordinates that approximately define my
# face and neck region (i.e., all visible skin)
rect = (151, 43, 236, 368)
```

**第 25 行**定义图像中面部的边界框坐标。这些 *(x，y)*-坐标是通过鼠标悬停在图像中的像素上并由我记录下来的方式手动确定的*。你可以用大多数照片编辑软件来完成，包括 Photoshop 或免费的替代软件，如 GIMP 和你在网上找到的其他应用程序。*

```py
# allocate memory for two arrays that the GrabCut algorithm internally
# uses when segmenting the foreground from the background
fgModel = np.zeros((1, 65), dtype="float")
bgModel = np.zeros((1, 65), dtype="float")

# apply GrabCut using the the bounding box segmentation method
start = time.time()
(mask, bgModel, fgModel) = cv2.grabCut(image, mask, rect, bgModel,
	fgModel, iterCount=args["iter"], mode=cv2.GC_INIT_WITH_RECT)
end = time.time()
print("[INFO] applying GrabCut took {:.2f} seconds".format(end - start))
```

```py
# the output mask has for possible output values, marking each pixel
# in the mask as (1) definite background, (2) definite foreground,
# (3) probable background, and (4) probable foreground
values = (
	("Definite Background", cv2.GC_BGD),
	("Probable Background", cv2.GC_PR_BGD),
	("Definite Foreground", cv2.GC_FGD),
	("Probable Foreground", cv2.GC_PR_FGD),
)

# loop over the possible GrabCut mask values
for (name, value) in values:
	# construct a mask that for the current value
	print("[INFO] showing mask for '{}'".format(name))
	valueMask = (mask == value).astype("uint8") * 255

	# display the mask so we can visualize it
	cv2.imshow(name, valueMask)
	cv2.waitKey(0)
```

```py
# we'll set all definite background and probable background pixels
# to 0 while definite foreground and probable foreground pixels are
# set to 1
outputMask = np.where((mask == cv2.GC_BGD) | (mask == cv2.GC_PR_BGD),
	0, 1)

# scale the mask from the range [0, 1] to [0, 255]
outputMask = (outputMask * 255).astype("uint8")

# apply a bitwise AND to the image using our mask generated by
# GrabCut to generate our final output image
output = cv2.bitwise_and(image, image, mask=outputMask)
```

这里我们产生了两种可视化效果:

1.  GrabCut 输出掩码
2.  输出图像(背景被遮挡)

```py
# show the input image followed by the mask and output generated by
# GrabCut and bitwise masking
cv2.imshow("Input", image)
cv2.imshow("GrabCut Mask", outputMask)
cv2.imshow("GrabCut Output", output)
cv2.waitKey(0)
```

既然 GrabCut with bounding box 初始化已经实现，让我们继续将它应用到我们的输入图像。

### 边界框 GrabCut 结果

首先使用这篇博文的 ***【下载】*** 部分下载源代码和示例图片。

从那里，打开一个终端，并执行以下命令:

```py
$ python grabcut_bbox.py
[INFO] applying GrabCut took 1.08 seconds
[INFO] showing mask for 'Definite Background'
[INFO] showing mask for 'Probable Background'
[INFO] showing mask for 'Definite Foreground'
[INFO] showing mask for 'Probable Foreground'
```

在*左侧，*您可以看到原始输入图像，而在*右侧，*您可以看到同一张脸，在脸/脖子区域周围绘制了一个边界框(该边界框对应于`grabcut_bbox.py`脚本中的`rect`变量)。

我们的目标是使用 GrabCut 和 OpenCV 从上面的图像中自动分割出面部和颈部区域。

接下来，你可以从第 45-60 行看到我们的输出，在这里我们可视化了明确的和可能的背景和前景分割:

最后，我们有 GrabCut 本身的输出:

在左边的*，*是我们的原始输入图像。

右边的*和*显示的是 GrabCut 生成的输出蒙版，而*底部的*显示的是将蒙版应用到输入图像的输出——**注意我的脸部和颈部区域是如何通过 GrabCut 干净地分割和提取的。**

### 使用 OpenCV 的 GrabCut:使用掩码初始化

之前，我们学习了如何使用边界框初始化 OpenCV 的 GrabCut——但是实际上还有第二个*方法来初始化 grab cut。*

**使用遮罩，我们可以提供图像中对象的*近似*分割。** GrabCut 然后可以迭代地应用图切割来改进分割，并从图像中提取前景。

这些掩码可以通过以下方式生成:

*   在 Photoshop、GIMP 等照片编辑软件中手动创建。
*   应用基本的图像处理操作，例如阈值处理、边缘检测、轮廓滤波等。
*   利用基于深度学习的分段网络(例如，屏蔽 R-CNN 和 U-Net)

如何生成遮罩与 GrabCut 无关。只要你有一个近似图像中对象分割的遮罩，*你就可以使用 GrabCut 来进一步改善分割。*

让我们看看 GrabCut with mask 初始化是如何工作的。

打开项目目录结构中的`grabcut_mask.py`文件，并插入以下代码:

```py
# import the necessary packages
import numpy as np
import argparse
import time
import cv2
import os

# construct the argument parser and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-i", "--image", type=str,
	default=os.path.sep.join(["images", "lighthouse.png"]),
	help="path to input image that we'll apply GrabCut to")
ap.add_argument("-mask", "--mask", type=str,
	default=os.path.sep.join(["images", "lighthouse_mask.png"]),
	help="path to input mask")
ap.add_argument("-c", "--iter", type=int, default=10,
	help="# of GrabCut iterations (larger value => slower runtime)")
args = vars(ap.parse_args())
```

同样，我们最著名的进口产品是 OpenCV 和 NumPy。如果您需要设置系统来执行 GrabCut with mask 初始化，请遵循*“配置您的开发环境”*部分的说明。

```py
# load the input image and associated mask from disk
image = cv2.imread(args["image"])
mask = cv2.imread(args["mask"], cv2.IMREAD_GRAYSCALE)

# apply a bitwise mask to show what the rough, approximate mask would
# give us
roughOutput = cv2.bitwise_and(image, image, mask=mask)

# show the rough, approximated output
cv2.imshow("Rough Output", roughOutput)
cv2.waitKey(0)
```

```py
# any mask values greater than zero should be set to probable
# foreground
mask[mask > 0] = cv2.GC_PR_FGD
mask[mask == 0] = cv2.GC_BGD
```

```py
# allocate memory for two arrays that the GrabCut algorithm internally
# uses when segmenting the foreground from the background
fgModel = np.zeros((1, 65), dtype="float")
bgModel = np.zeros((1, 65), dtype="float")

# apply GrabCut using the the mask segmentation method
start = time.time()
(mask, bgModel, fgModel) = cv2.grabCut(image, mask, None, bgModel,
	fgModel, iterCount=args["iter"], mode=cv2.GC_INIT_WITH_MASK)
end = time.time()
print("[INFO] applying GrabCut took {:.2f} seconds".format(end - start))
```

```py
# the output mask has for possible output values, marking each pixel
# in the mask as (1) definite background, (2) definite foreground,
# (3) probable background, and (4) probable foreground
values = (
	("Definite Background", cv2.GC_BGD),
	("Probable Background", cv2.GC_PR_BGD),
	("Definite Foreground", cv2.GC_FGD),
	("Probable Foreground", cv2.GC_PR_FGD),
)

# loop over the possible GrabCut mask values
for (name, value) in values:
	# construct a mask that for the current value
	print("[INFO] showing mask for '{}'".format(name))
	valueMask = (mask == value).astype("uint8") * 255

	# display the mask so we can visualize it
	cv2.imshow(name, valueMask)
	cv2.waitKey(0)
```

```py
# set all definite background and probable background pixels to 0
# while definite foreground and probable foreground pixels are set
# to 1, then scale teh mask from the range [0, 1] to [0, 255]
outputMask = np.where((mask == cv2.GC_BGD) | (mask == cv2.GC_PR_BGD),
	0, 1)
outputMask = (outputMask * 255).astype("uint8")

# apply a bitwise AND to the image using our mask generated by
# GrabCut to generate our final output image
output = cv2.bitwise_and(image, image, mask=outputMask)
```

```py
# show the input image followed by the mask and output generated by
# GrabCut and bitwise masking
cv2.imshow("Input", image)
cv2.imshow("GrabCut Mask", outputMask)
cv2.imshow("GrabCut Output", output)
cv2.waitKey(0)
```

同样，为了结束我们的脚本，我们显示了应用遮罩后 GrabCut 的输入`image`、GrabCut `outputMask`和`output`。

现在已经实现了 GrabCut mask 初始化，让我们继续用我们自己的示例图像来测试它。

### 屏蔽 GrabCut 结果

我们现在准备使用 OpenCV 和 GrabCut 通过遮罩初始化来分割图像。

首先使用本教程的 ***【下载】*** 部分下载源代码和示例图像。

从那里，打开一个终端，并执行以下命令:

```py
$ python grabcut_mask.py
[INFO] applying GrabCut took 0.56 seconds
[INFO] showing mask for 'Definite Background'
[INFO] showing mask for 'Probable Background'
[INFO] showing mask for 'Definite Foreground'
[INFO] showing mask for 'Probable Foreground'
```

在左边的*，*你可以看到我们的原始输入图像。在*右侧*你可以看到通过屏蔽初始化应用 GrabCut 的输出。

右边*的图像显示了与灯塔相关的遮罩。为了这篇博文/例子，我在 Photoshop 中手工创建了这个蒙版；然而，这里可以使用任何能够产生掩模的算法(例如通过阈值处理、边缘检测、轮廓的基本图像处理；基于深度学习的细分；等等。)**注意蒙版/分割不是很“干净”——我们可以很容易地看到背景的蓝天“漏”进了我们的蒙版。***

从那里，我们可以分别想象背景和前景的确定和可能的遮罩:

作为参考，左边的*显示我们的输入图像。*

右边的*显示了 GrabCut 生成的输出遮罩，而底部的*显示了将 GrabCut 创建的遮罩应用到原始输入图像的输出。**

**注意，我们已经清理了我们的分割**——天空的蓝色背景已经被移除，而灯塔作为前景被留下。

唯一的问题是，灯塔中实际聚光灯所在的区域被标记为背景:

这里的问题是，灯塔中灯光所在的区域或多或少是透明的，导致蓝天背景透过，从而导致 GrabCut 将这个区域标记为背景。

你可以通过更新你的蒙版来解决这个问题，当从磁盘加载你的蒙版时使用明确的背景(即`cv.GC_BGD`)。我将把这作为一个练习留给你，读者，去实现。

### 为什么 GrabCut 是好的，但不是完美的

GrabCut 是我最喜欢的计算机视觉算法之一，但它并不完美。

此外，基于深度学习的分割网络，如更快的 R-CNN 和 U-Net，可以*自动*生成可以从背景中分割对象(前景)的遮罩——**这是否意味着 GrabCut 在深度学习时代无关紧要？**

*其实，远非如此。*

虽然更快的 R-CNN 和 U-Net 是超级强大的方法，但它们会导致面具有点乱。我们可以使用 GrabCut 来帮助清理这些面具。我将在以后的博客文章中向你展示如何做到这一点。

## 摘要

在本教程中，您学习了如何使用 OpenCV 和 GrabCut 算法来执行前景分割和提取。

GrabCut 算法通过`cv2.grabCut`函数在 OpenCV 中实现，并且可以通过以下任一方式初始化:

1.  一个边界框，指定要在输入图像中分割的对象的位置
2.  近似图像中对象的像素位置的遮罩

GrabCut 算法采用边界框/遮罩，然后迭代地逼近前景和背景。

而基于深度学习的图像分割网络(例如屏蔽 R-CNN 和 U-Net)在实际检测图像中物体的和*近似屏蔽*时往往更强大，我们知道这些屏蔽可能不够完美——**我们实际上可以使用 GrabCut 来清理这些分割网络返回的“混乱”屏蔽！**

在未来的教程中，我将向您展示如何做到这一点。

**要下载这篇文章的源代码(并在未来教程在 PyImageSearch 上发布时得到通知)，*只需在下面的表格中输入您的电子邮件地址！*****